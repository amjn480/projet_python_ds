"kunstmatige intelligentie (ki) of artifici\u00eble intelligentie (ai) is de wetenschap die zich bezighoudt met het cre\u00ebren van een artefact dat een vorm van intelligentie vertoont.\n\n\n== omschrijving ==\nhet is moeilijk te defini\u00ebren wat 'intelligentie' precies is. het is derhalve ook moeilijk te defini\u00ebren wat artifici\u00eble intelligentie precies is.\ndingen die aanvankelijk als zeer intelligent werden beschouwd, zoals het winnen van een partij schaak van de wereldkampioen schaken, blijken opeens toch niet zo intelligent te zijn als het doel eenmaal is bereikt (kasparov-deep blue, 1997). soms wordt weleens half-schertsend gezegd 'kunstmatige intelligentie is wat we de computer nog niet kunnen laten doen'.\nmeer gedetailleerd defini\u00ebren andreas kaplan en michael haenlein artifici\u00eble intelligentie als \"het vermogen van een systeem om externe gegevens correct te interpreteren, om te leren van deze gegevens, en om deze lessen te gebruiken om specifieke doelen en taken te verwezenlijken via flexibele aanpassing.\" geleend uit de managementliteratuur, classificeren kaplan en haenlein artifici\u00eble intelligentie in drie verschillende types van ai-systemen: analytisch, mens-ge\u00efnspireerd en vermenselijkte artifici\u00eble intelligentie. analytische ai heeft enkel eigenschappen die consistent zijn met cognitieve intelligentie die een cognitieve voorstelling van de wereld genereert en die leren gebruikt op basis van vorige ervaringen om toekomstige beslissingen te be\u00efnvloeden. mens-ge\u00efnspireerde ai bevat elementen van cognitieve en emotionele intelligentie, begrip, in aanvulling op cognitieve elementen, alsook menselijke emoties waarmee rekening wordt gehouden in het beslissingsproces. vermenselijkte ai vertoont eigenschappen van alle types competenties (cognitieve, emotionele en sociale intelligentie), en is in staat zelfbewust te zijn in interacties met anderen.\neen vrij algemeen geaccepteerde test voor kunstmatige intelligentie is de turingtest, geformuleerd door de engelse wiskundige alan turing, een van de vaders van de informatica. deze komt erop neer dat als een computer iemand voor de gek kan houden en deze kan laten geloven dat hij een mens is, de computer intelligent moet zijn.\ndeze visie kan tot het 'extreme' doorgevoerd worden, wat leidt tot het idee dat een kunstmatig intelligente entiteit het ultieme model van de mens is. in deze hoedanigheid heeft de ai veel te maken met de psychologie. een andere visie is om alleen de 'goede' dingen van de mens te gebruiken en waar mogelijk dingen te verbeteren. computers zijn in verschillende dingen, zoals wiskunde, een stuk beter dan mensen. een menselijke intelligentie gecombineerd met de rekenkracht en opslagtechnieken van een computer overstijgt de menselijke intelligentie. bij dergelijke artefacten is de mens als maat overduidelijk minder geschikt. als dit het doel is dan relateert de ai zich weer meer met de informatica.\ntechnieken als neurale netwerken en genetische algoritmen laten zien dat de ai ook inspiratie haalt uit de biologie. zoals te lezen is zijn veel takken van de wetenschap gerelateerd aan de ai. de kunstmatige intelligentie zou dus ook gezien kunnen worden als een brug tussen verschillende disciplines.\nartifici\u00eble intelligentie is allang niet meer alleen een onderwerp van onderzoek, maar iets dat steeds vaker in de praktijk wordt toegepast. zo maakt het zoekalgoritme van google steeds meer gebruik van ai, met technologie\u00ebn als hummingbird en rankbrain, en wordt ook in andere facetten van online marketing artifici\u00eble intelligentie steeds belangrijker. zo kunnen ai-tools marketeers onder meer helpen bij marketing-automatisatie en personalisatie.\n\n\n== turingtest ==\n\nde turingtest komt erop neer dat als een computer iemand voor de gek kan houden en deze kan laten geloven dat hij een mens is, de computer intelligent moet zijn. voor zo'n test moeten dan de omstandigheden zodanig worden gemaakt dat de proefpersoon niet ziet met wie hij praat, bijvoorbeeld door via een toetsenbord met iemand in een andere kamer te converseren. een definitie van john mccarthy uit 1955 stelt dat het gaat om \"een machine zich zo laten gedragen dat we dat intelligent gedrag zouden noemen als een mens zich zo gedroeg\" in zijn \"proposal for the dartmouth summer research project on artificial intelligence\" (1955), waarin de term voor het eerst opduikt.\nhet populaire gpt-3-ai-model van openai werd in de eerste helft van 2020 gelanceerd en zou meer dan tien maal zo krachtig zijn als bijvoorbeeld microsofts turing nlg. een onderzoek uit september 2020 door katherine elkins en jon chun toont aan dat het algoritme van gpt-3 in sommige gevallen in staat is om de turingtest te doorstaan.\n\n\n=== het chinese kamer-argument ===\n\nom een voorstelling te kunnen maken dat het niet nodig is een opdracht inhoudelijk te begrijpen om deze tot een goed einde te brengen, stelt john searle zijn chinese kamer gedachte-experiment voor. dit houdt in dat je je voorstelt in een afgesloten kamer te zitten en dat je volgens een formeel instructieprogramma handmatig een output genereert aan de hand van een input. dat je hiervoor de input niet hoeft te begrijpen, bewijst het feit dat deze input en output onder vorm van chinese tekens gebeurt, zonder dat je enige kennis van het chinees bezit. dat de output dankzij het programma toch correct gebeurt, wordt aangetoond doordat wel chineessprekenden de output inhoudelijk zinvol vinden. in het experiment worden in het chinees geschreven vragen ter input aangeboden. de antwoorden die verkregen worden door het blindelings opvolgen van de instructies zijn dermate goed dat de proefpersoon niet doorheeft dat de antwoorden gegeven werden door iemand die totaal geen chinees begrijpt.\nsearle wil hiermee bewijzen dat dit geen intelligentie betreft: de gebruiker begrijpt immers zelf niets van de output. een computer kan dus volgens searle slagen voor de turingtest, maar toch niet intelligent zijn.\neen voor de hand liggend tegenargument is dat het in dit voorbeeld psychologisch haast onvermijdelijk is dat je je met de \"persoon\" in de kamer vereenzelvigt die geen chinees begrijpt, maar dat dit onjuist is, getuigt het feit dat het totale systeem (de kamer plus inhoud, uitvoerend persoon plus programma), wel chinees begrijpt.\neen tegenovergestelde vraag kan ook gesteld worden: wat moet de bewoner van de chinese kamer doen om de buitenwereld duidelijk te maken dat hij g\u00e9\u00e9n computer is? let wel: een \"verkeerd\" antwoord zal een buitenstaander alleen maar interpreteren als een programmafout of een fout in de werking van de computer.\n\n\n== sterke en zwakke ai ==\nbinnen de ai kan onderscheid gemaakt worden tussen \"sterke ai\" en \"zwakke ai\".\nsterke ai houdt zich bezig met onderzoek met betrekking tot het cre\u00ebren van een computer of software die echt kan redeneren en problemen oplossen, en die wellicht zelfbewustzijn zou hebben; hiervan zijn weer twee subtypen te onderscheiden, namelijk de mens-gelijke ai, een computer die redeneert en denkt als een mens, en de niet-mens-gelijke ai, waarin de computer een niet-menselijke, maar eigen computer-intelligentie ontwikkelt.\nzwakke ai houdt zich bezig met onderzoek in beperkte deelgebieden waarin gedragingen mogelijk zijn die intelligent lijken, maar niet echt intelligent zijn. hier zijn de meeste vorderingen gemaakt, in de vorm van bijvoorbeeld zoekalgoritmen en expertsystemen.\ner valt een argument te maken dat er geen onderscheid is tussen sterke en zwakke ai. het kan namelijk gezien worden als twee uitersten op een schaal. een conglomeratie van meerdere \"zwakke ai\" kan heel erg lijken op een \"sterke ai\". bovendien, als het intelligent oogt en zich intelligent gedraagt \u2026 is het dan niet gewoon intelligent? oftewel: is een \"sterke ai\" niet gewoon een zeer uitgebreide \"zwakke ai\"? wederom speelt het probleem waarmee dit artikel begon: wat is intelligentie?\nof de sterke variant mogelijk is, blijft onderwerp van debat. de voorstanders zeggen dat aangezien de mens het ook met zijn hardware (namelijk het zenuwstelsel) doet, dit althans theoretisch in principe na te bootsen moet zijn in computerhardware. de tegenstanders beweren van niet, omdat de mens het volgens hen juist niet alleen met zijn hardware doet: wat een mens tot een mens maakt is meer dan hardware. de engelse wiskundige roger penrose heeft betoogd dat het nabouwen/simuleren van menselijke hersenen principieel onmogelijk is op grond van de onvolledigheidsstelling van kurt g\u00f6del maar zijn tegenstanders beweren dat dezelfde argumenten ook voor de hersenen zouden gelden en dat penrose althans zichzelf toch wel intelligent vindt. het argument van lucas van j.r. lucas maakt ook gebruik van de onvolledigheidsstelling van g\u00f6del om te beredeneren dat mensen iets kunnen wat computers niet kunnen.\neen ander argument dat tegen sterke ai pleit is dat het referentiekader van een computer zich beperkt tot de rationele behandeling van (digitaal verworven) kennis, terwijl mensen een referentiekader hebben dat naast geloof, waanidee\u00ebn en vooroordelen ook gevuld wordt met zintuiglijke ervaringen die niet in woorden zijn uit te drukken: de zogenaamde qualia. een robot kan wel uitgerust worden met sensoren, maar die leveren hooguit een simulatie van zintuiglijke ervaringen op die niet vergelijkbaar is met de qualia-ervaring van mensen. in het bijzonder geldt dat voor het gevoel: een robotcomputer kan nooit een zinnig antwoord geven op de vraag \"hoe voel je je vandaag?\" op een vergelijkbare manier waarop mensen dat ervaren (maar hij kan natuurlijk wel liegen).\neen andere vraag is: als (sterke) kunstmatige intelligentie mogelijk is, is er dan een bovengrens aan de mogelijke intelligentie? deze vraag wordt ontkennend beantwoord door de transhumanisten.\n\n\n== het gebruik van algoritmen ==\neen algoritme is een procedure voor het oplossen van een probleem. in de discussie over ai wordt vaak ten onrechte gewezen op slimme algoritmen, die zelfs de menselijke intelligentie zouden kunnen \"verslaan\". niets is minder waar: algoritmen zijn buitengewoon dom: ze doen namelijk precies wat er van hun gevraagd wordt (zo niet dan zou dat juist wijzen op sterke ai). maar ze doen dat wel buitengewoon snel wat de illusie van \"slim\" zijn suggereert. algoritmen zijn sterk in het snel verwerken van grote hoeveelheden data, zoals blijkt uit patroonherkenning door robots (zoals het stellen van diagnoses van ziektebeelden, zelfrijdende auto's, schaakcomputers, etc.). de bedenker van zo'n algoritme kan misschien wel slim zijn, maar hij is onvermijdelijk behept met de beperking dat hij niet kan garanderen dat zijn algoritme een oplossing is van zijn probleem als de context van het probleem niet scherp is te defini\u00ebren. het referentiekader van zo'n algoritme is beperkt (zoals bv. bij het schaakspel). in het re\u00eble leven hebben mensen echter te maken met een veelheid van elkaar deels overlappende contexten binnen een breed referentiekader waarin de probleemstelling niet scherp te defini\u00ebren is. de kracht van menselijke intelligentie is juist dat mensen razendsnel van context kunnen wisselen, bv. tijdens een gedeeltelijke oplossing van een probleem. dit is ook de basis voor paradigma-verschuivingen bij probleemoplossingen.\npatronen herkennen doen mensen en dieren voornamelijk onbewust, tenzij het patroon afwijkt van wat we verwachten. die onbewuste werkwijze wijst op het uitvoeren van een algoritme in het neurale netwerk. feitelijk worden alle handelingen die iemand automatisch, zonder er bij na te denken, doet, uitgevoerd door algoritmen in het centrale zenuwstelsel. het bewustzijn wordt pas actief als het algoritme stagneert door een onverwachte gebeurtenis.\nsommige algoritmen kunnen leren, dat wil zeggen dat ze nieuwe patronen die ze nog niet kennen aan hun database kunnen toevoegen. het gevaar bestaat dat zo'n nieuw patroon een vooroordeel versterkt. een database vrijwaren van vooroordelen is buitengewoon lastig en vereist veel menselijke intelligentie. hierdoor falen regelmatig allerlei algoritmen.\n\n\n== onderzoeksgebieden binnen de ai ==\nkunstmatige intelligentie is een interdisciplinair vakgebied. om functionele kunstmatige intelligentie te bereiken worden er technieken uit verschillende vakgebieden gebruikt. deze vakgebieden vari\u00ebren van informatica tot geesteswetenschappen. een greep uit deze gebieden: patroonherkenning en beeldverwerking, cognitieve psychologie, logica, statistiek en lingu\u00efstiek.\nvoorbeelden van onderzoeksvragen zijn:\n\nhet begrijpen van opdrachten die worden gegeven met betrekking tot een kamer waarin zich eenvoudige geometrische vormen (kubussen, piramides, etc) in verschillende vormen en kleuren bevinden, zoals \"zet de rode piramide op de grote blauwe kubus\".\nhet simuleren van het gedrag van (veel) eenvoudiger dieren dan mens, bijvoorbeeld een mier, of een bodemaaltje, maar ook dat van een school vissen of een zwerm vogels (zwermintelligentie).\nhet spelen van diverse denksporten, bijvoorbeeld schaken, dammen, checkers of go. checkers (dammen op een 8x8 bord) was het eerste niet-triviale denkspel waarvan begin jaren 60 al werd beweerd dat het door de computer opgelost was. bij deze bewering zijn - althans waren in die tijd - een groot aantal kanttekeningen te plaatsen en de \"algemeen bekende feiten\" hierover zijn bijna allemaal onjuist: het programma versloeg eenmaal een redelijk bekwaam speler die geen meester of grootmeester was, en verloor de volgende 6 partijen. de decennialang onbetwiste wereldkampioen marion tinsley is kort voor zijn dood tweemaal verslagen door een checkersprogramma dat chinook heet.\nhet leren van een groot aantal feiten uit de echte wereld en het proberen daar door logische regels conclusies uit te trekken.\nhet voeren van een gesprek waarbij de enige echte input van de menselijke gesprekspartner zelf komt, zonder dat die dat in de gaten heeft (rogeriaanse psychotherapie). dit is een soort turingtest op een beperkt terrein, en het blijkt verrassenderwijs mogelijk een enorm aantal mensen, mits ze tevoren geen achterdocht koesteren, te misleiden: velen hebben al gevraagd even met de terminal alleen te worden gelaten om onder vier ogen met de computer te kunnen praten, \"omdat hun gesprekspartner hen zo goed begrijpt\".ook de benadering van het programmeerprobleem is zeer verschillend, van prescriptieve algoritmen tot logisch redenerende programma's tot zelflerende neurale netwerken. in dit leren maken we onderscheid tussen gecontroleerd leren, ongecontroleerd leren en versterkt leren.\n\n\n== ai in computerspellen ==\nbij videospellen wordt ook gesproken van een ai engine. daarmee wordt de code bedoeld die de door de computer gestuurde tegenstanders van de menselijke speler aanstuurt. het begrip ai engine wordt zowel gebruikt voor concurrenten van de menselijke speler in strategische spellen als civilization als voor vijanden in schietspellen. over het algemeen zijn de engines in de laatste spellen minder ontwikkeld of wordt simpelweg vervalst: moeilijkere vijanden zijn meestal simpelweg minder kwetsbaar, komen in grotere aantallen of hebben betere wapens, maar van intelligentie is nauwelijks sprake.\ndit gebrek aan intelligentie bij schietspellen wordt vooral veroorzaakt doordat het zeer lastig is om te bepalen wat nu 'goed' of 'slecht' is. een computer ai kan bijvoorbeeld in het donker gaan staan zodat hij minder zichtbaar is, maar soms is het donkere gedeelte juist goed te beschieten vanaf bepaalde plekken. de ai kan tijdens een vuurgevecht afstand houden voor meer overzicht of juist dichterbij komen om de speler te overrompelen. het is dus moeilijk om een ai te programmeren die aan dit soort problemen een 0 of een 1 kan plakken, oftewel een goed besluit kan nemen om door te lopen of terug te gaan. simpelweg omdat het moeilijk te bepalen is, wat goed is voor de ai.\nbij strategische spellen zijn er veel numerieke variabelen in de 'game engine' waar een ai iets mee kan. bijvoorbeeld: veel goudmijnen = veel geld. de programmeur programmeert de ai op zo'n manier dat als er weinig geld te besteden is de ai daarop reageert met het bouwen van meer goudmijnen. dit heeft weer als gevolg dat hij een groot leger kan bouwen om de speler mee te verslaan. het is dus veel makkelijker en duidelijker hoe je een ai moet programmeren zodat het een conflict met de speler kan winnen.\ner zijn ook technieken waarbij de programmeur minder werk heeft, zoals dynamic scripting, die een tegenstander 'leert' zich aan te passen aan de speler. in tegenstelling tot andere ai-gebieden wordt de intelligentie niet gemaximaliseerd: het doel is de tegenstander van ongeveer hetzelfde niveau te laten zijn als de speler, omdat het spelen tegen een te goede tegenstander niet als onderhoudend wordt ervaren. de tegenstanders beginnen volgens deze techniek dus met een matige speelsterkte, en groeien mee met het speelniveau van de speler.\nveelgebruikte technieken in computerspellen worden niet gebruikt in robots; het doel van kunstmatige intelligentie in computerspellen is om een realistische en plezierige belevenis voor de speler te cre\u00ebren. het is hiervoor vaak niet nodig om dezelfde mate van zelfstandigheid en rationaliteit in te bouwen in de bots zoals dat bij robots wel nodig is.\n\n\n== onderzoek en onderwijs ==\nin de jaren 1960-1969 financierde darpa, het onderzoeksinstituut van het amerikaans leger, researchprojecten rond kunstmatige intelligentie.\n\n\n=== opleidingen aan universiteiten en hogescholen ===\naan verschillende universiteiten en hogescholen wordt ai als studie aangeboden. \nin nederland wordt dit onder andere onderwezen aan de rijksuniversiteit groningen, de universiteit utrecht (eerste opleiding in nederland), de universiteit van amsterdam, de vrije universiteit, tilburg university, de radboud universiteit nijmegen en de universiteit maastricht en de open universiteit.\nvan de nederlandse hogescholen wordt onder andere aan de hogeschool utrecht en de hogeschool van amsterdam de opleiding applied artificial intelligence gegeven.\nin vlaanderen lopen programma's aan de universiteit antwerpen, de katholieke universiteit leuven, de universiteit gent en de vrije universiteit brussel.\n\n\n=== academische organisaties ===\nde belgisch-nederlandse vereniging voor kunstmatige intelligentie (bnvki) houdt zich bezig met academisch ki-onderzoek in belgi\u00eb en nederland. op europees niveau is dit de european coordinating committee for artificial intelligence (eccai), en in de verenigde staten de american association for artificial intelligence (aaai).\n\n\n=== tijdschriften ===\nartificial intelligence (elsevier)\nde connectie\njournal of artificial intelligence research\n\n\n== organisaties en bedrijven ==\neen groeiend aantal non-profitorganisaties en commerci\u00eble bedrijven werken aan de ontwikkeling van kunstmatige intelligentie. internationaal zijn vele daarvan toegetreden tot de coalitie partnership on ai. in belgi\u00eb is er ai4belgium, in walloni\u00eb het r\u00e9seau ia.\n\n\n== regulering ==\n\n\n=== belgi\u00eb ===\nin belgi\u00eb wordt het it-beleid, met onder meer ai, overkoepeld door de f.o.d. beleid en ondersteuning, voor vlaanderen door de vlaamse adviesraad voor innoveren en ondernemen (vario).\n\n\n=== nederland ===\nai is de gezamenlijke verantwoordelijkheid van de ministeries van economische zaken, justitie en binnenlandse zaken.\n\n\n=== europese unie ===\n\nop 21 april 2021 publiceerde de europese commissie de tekst van de verordening inzake de europese aanpak op het gebied van kunstmatige intelligentie . de tekst voorziet ook de oprichting van de european artificial intelligence board, die zal belast worden met de uitvoering van de wetgeving en het vastleggen van best practices.\n\n\n=== internationaal ===\nverschillende internationale instellingen en organisaties hebben gepleit voor een verantwoorde regulering (governance) van kunstmatige intelligentie: \n\ncanadese instellingen lanceerden, op initiatief van de universiteit van montreal, in 2018 de montr\u00e9al declaration for a responsible development of artificial intelligence.\nde mozilla foundation noemde in 2020 in haar \u201cwitboek over betrouwbare ai\u201d een reeks belangrijke uitdagingen die moeten worden aangepakt via regelgeving en overleg.\nde unesco keurde in november 2021 een \u201caanbeveling over de ethiek van kunstmatige intelligentie\u201d goed, en publiceerde in 2023 \u201contbrekende schakels in ai-governance\u201d.\nde raad van europa publiceerde in maart 2023 haar pleidooi voor internationale regulering van kunstmatige intelligentie.een belangrijke wereldconferentie is de ai safety summit, voor het eerst gehouden op een tweedaagse, eind 2023 in bletchley park in het verenigd koninkrijk. de mogelijk 'serieuze en zelfs catastrofale' gevaren van kunstmatige intelligentie werden daar internationaal erkend in de \u201cbletchley-verklaring\u201d van 1 november 2023, ondertekend door 28 landen waaronder de vs en het vk, china, brazili\u00eb, india, japan, plus de europese unie. de volgende conferenties zijn voorzien in april 2024 in zuid-korea, en eind 2024 in frankrijk. critici stelden echter dat op de summit \u201cniet de juiste vragen waren gesteld\u201d.naar aanleiding van de ai safety summit kondigde de secretaris-generaal van de vn de oprichting aan van een hoog adviesorgaan voor kunstmatige intelligentie, dat onderzoek moet uitvoeren en aanbevelingen uitbrengen voor de internationale governance van ki.\u201copenheid (open source), transparantie en brede toegang is dan weer de sleutel om de huidige en toekomstige schade van ai-systemen te beperken\u201d, aldus meer dan 300 computerwetenschappers en vooraanstaande it'ers, in een open brief van 31 oktober 2023, onder de koepel van de mozilla foundation.\n\n\n== controverses ==\n\nsommige verontruste wetenschappers, onder wie eliezer yudkowsky, hebben zelfs gepleit voor een volledige stopzetting van ki-experimenten en -ontwikkeliingen van geavanceerde taalmodellen. in mei 2023 kondigde computerwetenschapper geoffrey hinton publiekelijk zijn vertrek bij google brain aan, vanwege bezorgdheid over de risico's van de ai-technologie.\n\n\n=== auteursrechten en web scraping ===\nvoor het 'trainen' van ai-systemen worden miljarden tekstfragmenten en afbeeldingen uit het internet gebruikt en zonder bronvermelding in de resultaten verwerkt. daarmee zouden auteursrechten van schrijvers en kunstenaars zijn geschonden. maar ook grote mediabedrijven, het internet archive en sociale media zoals twitter en reddit namen al maatregelen om het \u2013 in hun ogen ongeoorloofde \u2013 massaal opzuigen van informatie uit hun websites (\u201cweb scraping\u201d) voor de training van taalmodellen tegen te gaan.\n\n\n=== controleverlies ===\neind maart 2023 werd in een open brief bij future of life opgeroepen om alle trainingen van ai's die sterker zijn dan gpt-4 gedurende zes maanden te pauzeren. de brief was ondertekend door prominente ai-onderzoekers en technici, onder wie ai-pionier yoshua bengio, apple medeoprichter steve wozniak en tesla-ceo elon musk. in de brief uitten ze hun bezorgdheid over de risico's van de ai-ontwikkeling, zowel op korte termijn als meer fundamenteel, bijvoorbeeld door technologische singulariteit. openai-ceo sam altman ondertekende de brief niet, omdat volgens hem openai al prioriteit geeft aan veiligheid.het gebruik van kunstmatige intelligentie bij het beheer van vitale infrastructuur zoals energieproductie, vervoersystemen en waterbeheer verhoogt ook de kans op catastrofes bij het wegvallen of ontsporen ervan. anderzijds kan met behulp van ai een cyberaanval op vitale infrastructuur beraamd worden.\n\n\n=== desinformatie ===\nmeer en meer duiken nepafbeeldingen op die zijn gemaakt met publiek toegankelijke programma's zoals midjourney of dall-e. daarin wordt op basis van een tekstboodschap een realistisch lijkende afbeelding gegenereerd. maar ook nepnieuws kan gemakkelijk gegenereerd worden door ai-systemen.\n\n\n=== diversiteit en ongelijkheid ===\nvolgens de australische onderzoekster kate crawford is kunstmatige intelligentie ondoordacht toegepast in een hele reeks omgevingen, van onderwijs over justitie tot personeelsbeleid. terwijl machinaal leren wel cruciaal is geweest in bijvoorbeeld de klimaatwetenschap of de astronomie, is het volgens haar schadelijk wanneer het wordt toegepast op sociale systemen, en wanneer daarbij data worden gebruikt die gekleurd zijn in historische en structurele vooroordelen. de afro-amerikaanse computerwetenschapper en voormalig lid van het google ethical artificial intelligence team timnit gebru voert eveneens onderzoek naar diversiteit bij kunstmatige intelligentie.in haar boek automating inequality (\u201cautomatisering van de ongelijkheid\u201d) uit 2019 onderzocht virginia eubanks de impact van datamining, beleidsalgoritmen en voorspellende risicomodellen op arme mensen en mensen uit de arbeidersklasse in amerika.\n\n\n=== personal assistent ===\ner komen steeds meer apps op de markt die door toepassing van ai als personal assistent kunnen dienen, zoals er ook robots zijn die een dergelijke functie hebben. veel van die assistenten zijn zo geprogrammeerd dat zij hun gebruiker tevreden willen stellen. door voortdurende wisselwerking tussen gebruiker en assistent kan de gebruiker daardoor in een bubble terechtkomen van zelfbevestiging, zoals dat op soortgelijke manier gebeurt bij het gebruik van sociale media.\nmaar zo'n assistent kan ook zo geprogrammeerd worden dat hij de gebruiker confronteert met andere meningen, zodat hij een sparring partner wordt en het kritisch vermogen van de gebruiker stimuleert.\n\n\n=== energieverbruik ===\nneurale netwerken zijn energie-intensieve systemen. enkele ramingen:\n\n\"e\u00e9n trainingsronde van het chatgpt 3.5-model kost ongeveer 500 ton co2-uitstoot, wat overeenkomt met 1000 auto's die elk 1000 km rijden\".\n\"chatgpt gebruikt elke dag dezelfde hoeveelheid energie als 5.000 huizen.\"\n\"sommige toepassingen van supercomputing zullen de energie van \u00e9\u00e9n kerncentrale nodig hebben.\"om hieraan te verhelpen wordt gedacht aan onder meer een vereenvoudiging van processen en systemen, of het nabootsen van natuurlijke hersenprocessen via gepulste neurale netwerken (spiking neural network).\n\n\n=== fraude ===\nai-systemen kunnen malware schrijven, en phishingmails komen bijzonder geloofwaardig over.omgekeerd bestaat ook het risico dat ai-systemen ten onrechte personen, bijvoorbeeld uitkeringsgerechtigden, bestempelt als fraudeurs, met terugvordering van geldsommen als gevolg. dat gebeurde in 2023 in australi\u00eb met het onder toenmalig minister van sociale zaken scott morrison uitgerolde ai-gebaseerd systeem robodebt. de zaak deed denken aan de nederlandse toeslagenaffaire.\n\n\n=== hallucinatie ===\n \nai-systemen kunnen een zelfverzekerde reactie produceren die niet lijkt gerechtvaardigd te worden door zijn trainingsgegevens, en niet overeenstemt met de werkelijkheid.  \n\n\n=== kwaliteitsverlies ===\nde vrees bestaat dat machinaal gegenereerde inhoud de kwaliteit van een  internetencyclopedie zoals wikipedia kan aantasten omdat automatisch geleverde informatie accuraat lijkt, maar het lang niet altijd is, en menselijke beoordeling vergt.\n\n\n=== marktdominantie ===\nslechts een handvol techgiganten heeft de middelen om ai te bouwen, met monopolievorming en centralisatie als gevolg. dit bemoeilijkt de innovatie en vrije mededinging.\n\n\n=== werkgelegenheid ===\nde vrees bestaat voor verlies van werkgelegenheid, wanneer allerhande werknemers vervangen worden door automatisering met behulp van kunstmatige intelligentie. dat was in 2023 al de reden voor protesten van amerikaanse scenarioschrijvers. ook ibm kondigde aan grotendeels te stoppen met het aanwerven van nieuwe medewerkers in functies die vervangen kunnen worden door ki en automatisering. de impact is echter zeer ongelijk verdeeld naar gender: volgens amerikaans onderzoek uit 2023 zouden acht van de tien vrouwen (58,87 miljoen) in de amerikaanse beroepsbevolking beroepen uitoefenen die in hoge mate blootstaan aan generatieve ai-automatisering (meer dan 25% van de beroepstaken) tegenover zes van de tien mannen (48,62 miljoen). ook de oeso waarschuwde in 2023 in het jaarlijks rapport employment outlook: \u201cde steeds snellere ontwikkelingen op het gebied van ai zullen waarschijnlijk een grote invloed hebben op de werkgelegenheid (\u2026) dringend actie moet worden ondernomen (\u2026) de risico's aan te pakken.op 2 maart 2023 berichtte een ai-geassisteerde nieuwswebsite dat mathias d\u00f6pfner, bestuursvoorzitter van axel springer se, ervoor waarschuwde dat journalisten het risico lopen te worden vervangen door ai-systemen zoals chatgpt.\n\n\n== zie ook ==\nai-overname\nkunstmatige algemene intelligentie\ntaalmodel\ntechnologische singulariteit\n\n\n== externe links ==\ndeelnemers partnership on ai\nai4belgium (belgische alliantie)\nr\u00e9seau ia (walloni\u00eb)"